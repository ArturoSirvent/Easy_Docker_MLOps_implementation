# Implementacion MLOps + IoT en Docker

Date Created: November 12, 2022 11:58 AM  
Epic: Seminarios Master  
Priority: High üî•  
Status: In Progress  

# Revisi√≥n e implementaci√≥n de un modelo mediante t√©cnicas de MLOps  

***********************Arturo Sirvent Fresneda***********************  

### Resumen

El objetivo de este trabajo ha sido el de crear un documento que por un lado resuma las t√©cnicas usadas para el despliegue autom√°tico de modelos de Machine Learning, y por otro lado, la implementaci√≥n concreta en una √°rea, haciendo uso de tecnolog√≠as disponibles para este prop√≥sito, como el uso de Docker, orquestaci√≥n de contenedores y API REST entre otras.

El caso pr√°ctico concreto en el que se ha trabajado, ha sido el de un sensor de humedad colocado en el exterior, el cual env√≠a de forma peri√≥dica informaci√≥n (mediante una API y protocolo HTTP) a un sistema centralizado donde la informaci√≥n se procesa. En dicho sistema centralizado, est√° corriendo un sistema autom√°tico que crea un modelo de predicci√≥n de los valores futuros de la humedad. Lo importante de todo esto, es que el modelo no es est√°tico, y este se va validando con el tiempo y nuevos datos, de esta forma logramos el ******deploy****** de un modelo, el cual recibe los datos haciendo uso de tecnolog√≠a IoT. 

*Nota: Sobre IoT no hubo ning√∫n seminario, pero me parec√≠a muy interesante realizar la implementaci√≥n realista en la que los datos se deben de recibir de forma remota de alg√∫n sensor.*

---

## Introducci√≥n

Es indudable que en los √∫ltimos a√±os se est√° llevando a cado la llamada ‚Äúdigitalizaci√≥n‚Äù de muchos procesos, entre estos no solo est√°n las migraciones de la informaci√≥n a nuevos formatos digitales, sino que tambi√©n se ha visto como poco a poco la sensorizaci√≥n el mundo del IoT y el **************edge computing************** ocupa m√°s espacio en la industria. Pero esto automatiza la parte relativa a la obtenci√≥n de la informaci√≥n, nos aun otro hueco que llenar con el procesado de dicha informaci√≥n. Aqu√≠ es donde entra en juego el MLOps, una serie de tecnolog√≠as y formad de trabajo que permiten contar con modelos de Machine Learning que produzcan resultados fiables pues est√°n siendo monitorizados-reentrenados-revisados constantemente. Mediante est√°s tecnologias, el Ingeniero de MLOps  puede (con la ayuda de otros roles esenciales) montar una infraestructura donde todo el ciclo de vida **********************************datos crudos ‚Äî> informaci√≥n********************************** puede ser automatizado, y de esta forma, se puede dedicar m√°s tiempo a la tarea realmente esencial en una empresa (u otro organismo), la de transformar ******************informaci√≥n ‚Äî> conocimiento.******************

El panorama de las tecnolog√≠as MLOps es abrumadoramente grande. Esta abundancia de recursos, parad√≥jicamente puede hacer incluso m√°s complicado aprender la disciplina, pues siempre se cuenta con la duda de si los recursos escogidos son los mejores y m√°s vers√°tiles. Tambi√©n el r√°pido desarrollo de metodolog√≠as, algoritmos, software, librer√≠as etc., hace que sea muy f√°cil desactualizarse si no se mantiene una actitud de constante investigaci√≥n y aprendizaje. 

Con la idea de prevenir esta desactualizaci√≥n, en este caso pr√°ctico se pretende hacer uso de la tecnolog√≠as de m√°s bajo nivel posible, que aun hacen posible una implementaci√≥n reducida y donde todos los pasos son personalizables y monitorizables. Es un poco este *****trade-off***** entre programaci√≥n de alto nivel y bajo nivel el que se pretende buscar. Por ejemplo, no vamos a programar un protocolo de comunicaci√≥n *machine to machine,* pero tampoco vamos a usar un medio de comunicaci√≥n que ya este montado completamente, usaremos python y la librer√≠a ********FastAPI******** para dar soporte a esta necesidad de comunicaci√≥n entre m√°quinas.

---

## Teor√≠a sobre MLOps, y ‚Äú*********Landscape*********‚Äù actual

MLOps nace como una variante de DevOps en la que se pretende usar esa metodolog√≠a pero a√±adiendo modelos de *Machine Learning* (no confundir con DataOps que se centra m√°s en la administraci√≥n de los datos). 

Como pilares del MLOps podr√≠amos poner:

![](images/Diagrama_en_blanco_(1).png)

No vamos a entrar en profundidad en cada uno de los pasos, pues hay muchos recursos en los cuales se extiende la idea de una forma muy extensa y rigurosa. En lugar de eso, creemos que es m√°s √∫til tener un conocimiento s√≥lido del flujo de trabajo, de la *********pipeline********* que se puede seguir al desarrollar un proyecto.  A√±adiendo en cada caso, una panor√°mica de los recursos disponibles para ello.

![](images/Untitled.png)

---

## Metodolog√≠a e Implementaci√≥n del Caso Pr√°ctico

Mi caso pr√°ctico va a contar con los siguientes componentes:

![images/parts_mlopswork.png](images/parts_mlopswork.png)

Primero se escribi√≥ el c√≥digo de la API Rest, usando FastAPI. Esto nos permitir√° tener el sensor y la unidad de procesamiento o servidor, en lugares separados, esto es especialmente importante cuando tenemos varios sensores repartidos por ah√≠.

Los datos recogidos mediante los sensores, eran almacenados en sistema de base de datos relacional, escog√≠ *Postgres*, pero cualquier otro podr√≠a haber funcionado (e.g. mySQl, Oracle ). Estos datos se versionaban usando DVC ( Nota: este paso es bastante innecesario para nuestro caso, sobre todo dada la naturaleza y la cantidad de datos con la que trabajamos, pero se pretender crear un entorno de trabajo lo m√°s completo y vers√°til posible, para as√≠ conocer las tecnolog√≠as en casos futuros que presenten mayor complejidad). 

Una vez contaba con datos para crear los modelos, usando un IDE (jupyter notebook en mi caso), desarroll√© el modelo usando las librer√≠as mencionadas anteriormente.

Durante todo este proceso, se hizo un seguimiento del c√≥digo con Git, y una estructuraci√≥n del proyecto con CookieCutter. Docker se uso para la generaci√≥n autom√°tica y simplificada de un entorno en el que poner a correr al modelo, un contenedor que est√© escuchando a que nos comuniquemos con el por medio de la API y cuando se lo solicitemos, ejecute el modelo para devolvernos el resultado. De esta forma, con Docker compose, el contenedor puede ser creado desde cero cada vez que pongamos el sistema a funcionar, y siempre funcionar√° exactamente igual, lo √∫nico que necesitamos es conocer la manera correcta de comunicarnos con el mediante la API.

En este punto ya tenemos un modelo funcional y una forma de comunicarnos con el para obtener las predicciones. El siguiente paso es hacerlo accesible. Para ello, creamos una aplicaci√≥n web usando Streamlit, que ser√≠a como el mejor equivalente a Shiny en Python. 

Tenemos 3 m√≥dulos separados que necesitan comunicarse para realizar la funci√≥n completa: 

1. Contener en Docker, con el modelo listo para predecir.
2. El dispositivo IoT enviando datos mediante API Rest.
3. La interfaz web creada con Streamlit, capaz de interactuar con el usuario.

![containers_diagrama_(1).png](images/containers_diagrama_(1).png)

Lo siguiente fue, crear el c√≥digo que une a los tres m√≥dulos. Este c√≥digo lee de la base de datos que se est√° rellenando por el sensor IoT. Pasa eso datos al modelo y recibe la predicciones, y finalmente las muestras por la interfaz gr√°fica. Entre medias, se permite que la interfaz gr√°fica modifique algunos argumentos internos para que por ejemplo, la predicci√≥n se haga a 5 d√≠as futuros y no a 1 etc. 

Por √∫ltimo, el despliegue se hace con un servidor apache que es el encargado de ‚Äúmostrar‚Äù todo al internet, para poder ser accedido por los usuarios. Y para actualizaci√≥n autom√°tica de datos y su monitorizaci√≥n (y reentreno si los resultados del modelo empeoraran mucho) se realiza con Cron(Linux) y mlflow.

---

## Resultados Caso Pr√°ctico y Conclusiones

Me ha sido imposible redactar la implementaci√≥n a tiempo, esta se puede encontrar en:

[https://github.com/ArturoSirvent/Easy_Docker_MLOps_implementation](https://github.com/ArturoSirvent/Easy_Docker_MLOps_implementation)

---
